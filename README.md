# Сканер ссылок на веб-сайте

Этот скрипт на Python позволяет сканировать веб-сайт и собирать информацию о внешних ссылках, битых ссылках и перенаправлениях (301) на всех внутренних страницах. Результаты сохраняются в виде Excel таблиц.

## Функциональные возможности

- **Внешние ссылки:** Сканирует все внутренние страницы сайта и собирает все внешние ссылки.
- **Битые ссылки:** Проверяет все внешние ссылки и определяет ссылки с некорректными статусами (отличные от 200 и 301).
- **Перенаправления:** Идентифицирует ссылки, которые перенаправляют (статус 301) и собирает конечные URL.

## Установка

1. Убедитесь, что у вас установлен Python 3.x.
2. Скачайте или склонируйте репозиторий.
3. Установите необходимые зависимости, запустив команду:

   ```bash
   pip install -r requirements.txt


ИСПОЛЬЗОВАНИЕ

1. Запустите скрипт:

    python main.py

2. Введите URL сайта, который вы хотите сканировать:

    http://example.com

3. Выберите режим работы:

    1: Только все внешние ссылки на всех внутренних страницах
    2: Битые ссылки (отличные от 200 и 301)
    3: Склеенные страницы (отдают 301)
    Введите номер режима: 1

4. Дождитесь завершения сканирования. Результаты будут сохранены в папку output в виде Excel файлов.

ОПИСАНИЕ КОДА

    - get_links(url): Получает все внутренние и внешние ссылки на указанной странице.
    - check_link(url): Проверяет статус указанной ссылки. При статусе 301 возвращает также ссылку для перенаправления.
    - save_to_excel(data, filename, columns): Сохраняет данные в Excel файл.
    - add_indexes(data): Добавляет индексы к данным для лучшего отображения в таблицах.
    - crawl_website(base_url, mode): Обходит сайт и собирает информацию в зависимости от выбранного режима.
    - setup_output_folder(folder_name): Настраивает выходную папку, создавая новую или удаляя существующую.
    - main(): Главная функция, инициализирует программу, запрашивает URL сайта и режим работы, запускает обход сайта и сохраняет результаты.

ПРИМЕР РАБОТЫ:

    Введите адрес сайта: http://example.com
    Выберите режим работы:
    1: Только все внешние ссылки на всех внутренних страницах
    2: Битые ссылки (отличные от 200 и 301)
    3: Склеенные страницы (отдают 301)
    Введите номер режима: 1
    Сканирование страницы: http://example.com ...
    Таблица с внешними ссылками сохранена в файл 'output/external_links.xlsx'

ТРЕБОВАНИЯ:

    Python 3.x
    requests
    BeautifulSoup4
    pandas

ЛИЦЕНЗИЯ:

    Этот проект лицензирован под MIT License.
